#!/usr/bin/env python
# encoding: utf-8


from __future__ import (absolute_import, division,
                        print_function, unicode_literals)


import os, re, sys
import argparse

sys.path.insert(0, os.path.sep.join([os.path.dirname(os.path.realpath(__file__)), "PyLib"]))
from Pipeliner import Pipeliner, Command


__example__ = "FusionInspector --left_fq ../BT474--ACACA--STAC2.left.fq --right_fq ../BT474--ACACA--STAC2.right.fq \
              --fusions fusion_gene_candidates.dat --out_dir myoutdir --out_prefix ladeda"


import logging
FORMAT = "%(asctime)-15s %(levelname)s %(module)s.%(name)s.%(funcName)s at %(lineno)d :\n\t%(message)s\n"
global logger
logger = logging.getLogger()
logging.basicConfig(filename='FusionInspector.log', format=FORMAT, filemode='w', level=logging.DEBUG)
# add a new Handler to print all INFO and above messages to stdout
ch = logging.StreamHandler(sys.stdout)
ch.setLevel(logging.INFO)
logger.addHandler(ch)



BASEDIR = os.path.dirname(__file__)
UTILDIR = os.sep.join([BASEDIR, "util"])

TRINITY_HOME = None #init below if --include_Trinity


"""
______         _            _____                          _
|  ___|       (_)          |_   _|                        | |
| |_ _   _ ___ _  ___  _ __  | | _ __  ___ _ __   ___  ___| |_ ___  _ __
|  _| | | / __| |/ _ \| '_ \ | || '_ \/ __| '_ \ / _ \/ __| __/ _ \| '__|
| | | |_| \__ \ | (_) | | | || || | | \__ \ |_) |  __/ (__| || (_) | |
\_|  \__,_|___/_|\___/|_| |_\___/_| |_|___/ .__/ \___|\___|\__\___/|_|
                                          | |
                                          |_|
                                                                                    

"""


class FusionInspector:

    def run(self):
        
        arg_parser = argparse.ArgumentParser(
            
            description = "Extracts a pair of genes from the genome, creates a mini-contig, aligns reads to the mini-contig, and extracts the fusion reads as a separate tier for vsiualization.",
            formatter_class=argparse.RawTextHelpFormatter
            )
        
        
        arg_parser.add_argument("--fusions", dest="chim_summary_files", type=str, default="", required=True,
                             help="fusions summary files (list, comma-delimited and no spaces)")
    
        arg_parser.add_argument("--genome_lib_dir", dest="genome_lib_dir", type=str, default=os.environ.get('CTAT_GENOME_LIB'),
                             help="genome lib directory - see http://FusionFilter.github.io for details")
        
        arg_parser.add_argument("--left_fq", dest="left_fq_filename", type=str, required=False, default=None,
                             help="left (or single) fastq file")
        
        arg_parser.add_argument("--right_fq", dest="right_fq_filename", type=str, required=False, default="", #intentionally not None
                             help="right fastq file (optional)")
        
        arg_parser.add_argument("--samples_file", dest="samples_file", type=str, required=False, default=None,
                             help="samples file (format: sample(tab)/path/left.fq(tab)/path/right.fq")
        
        arg_parser.add_argument("--out_dir", dest="str_out_dir", type=str, required=True, help="output directory")

        arg_parser.add_argument("--out_prefix", dest="out_prefix", type=str, default='finspector', help="output filename prefix")

        arg_parser.add_argument("--min_junction_reads", dest="min_junction_reads", type=int, required=False, default=0,
                             help="minimum number of junction-spanning reads required")
        
        arg_parser.add_argument("--min_sum_frags", dest="min_sum_frags", type=int, required=False, default=2,
                             help="minimum fusion support = ( # junction_reads + # spanning_frags )")

        arg_parser.add_argument("--min_novel_junction_support", dest="min_novel_junction_support", type=int, required=False, default=3,
                             help="minimum number of junction reads required if breakpoint lacks involvement of only reference junctions")

        arg_parser.add_argument("--min_spanning_frags_only", dest="min_spanning_frags_only", type=int, required=False, default=5,
                             help="minimum number of spanning frags if no junction reads are found")
        
        arg_parser.add_argument("--require_LDAS", type=int, required=False, default=1,
                             help = "require long double anchor support for split reads when no spanning frags are found")
        
        arg_parser.add_argument("--max_promiscuity", dest='max_promiscuity', type=int, required=False, default=10,
                             help="maximum number of partners allowed for a given fusion")
        
        arg_parser.add_argument("--min_pct_dom_promiscuity", dest="min_pct_dom_promiscuity", type=int, required=False, default=50,
                             help="for promiscuous fusions, those with less than this support of the dominant scoring pair " +
                             "are filtered prior to applying the max_promiscuity filter. ")
        
        arg_parser.add_argument("--min_per_id", dest="min_per_id", type=int, required=False, default=96,
                             help='minimum percent identity for a fusion-supporting read alignment')
        
        arg_parser.add_argument("--only_fusion_reads", default=False, action='store_true',
                             help="include only read alignments in output that support fusion" )
        
        arg_parser.add_argument("--capture_genome_alignments", default=False, action='store_true',
                             help='reports ref genome alignments too (for debugging only)')
                        
        arg_parser.add_argument("--include_Trinity", dest="include_Trinity", required=False, action = "store_true", default=False,
                             help="include fusion-guided Trinity assembly")

        arg_parser.add_argument("--prep_for_IGV", dest="prep_for_IGV", required=False, action="store_true", default=False,
                             help="generate bam, bed, etc., for use with IGV")

        arg_parser.add_argument("--write_intermediate_results", dest="write_intermediate_results", required=False, action="store_true",
                             default=False, help="generate bam, bed, etc., for intermediate aligner outputs")

        arg_parser.add_argument("--cleanup", dest="cleanup", required=False, action="store_true", default=False,
                             help="cleanup the fusion inspector workspace, remove intermediate output files")

        arg_parser.add_argument("--CPU", dest="CPU", required=False, type=int, default=4,
                             help="number of threads for multithreaded processes")
        
        arg_parser.add_argument("--annotate", dest="annotate", required=False, action='store_true', default=False,
                             help="annotate fusions based on known cancer fusions and those found in normal tissues")

        arg_parser.add_argument("--examine_coding_effect", dest='examine_coding_effect', required=False, action='store_true', default=False,
                             help='explore impact of fusions on coding sequences')
        

        arg_parser.add_argument("--aligner_path", default=None, type=str, help="path to the aligner tool (default: uses PATH setting)")
        
        arg_parser.add_argument("--fusion_contigs_only", action='store_true', default=False, help="align reads only to the fusion contigs") 

        arg_parser.add_argument("--extract_fusion_reads_dir", default=None, type=str, help="directory to write fusion evidence reads in fastq format")


        args_parsed = arg_parser.parse_args()


        if not (args_parsed.left_fq_filename or args_parsed.samples_file):
            print("Error, must specify --left_fq or --samples_file", file=sys.stderr)
            sys.exit(1)
        

        if args_parsed.include_Trinity:

            if not os.environ.has_key('TRINITY_HOME'):
                print("Error, need TRINITY_HOME environmental variable set and pointing to Trinity installation directory when --include_Trinity is enabled", file=sys.stderr)
                sys.exit(2)
    
            global TRINITY_HOME
            TRINITY_HOME = os.environ["TRINITY_HOME"]
    

        
        genome_lib_dir = args_parsed.genome_lib_dir
        if genome_lib_dir is None:
            raise RuntimeError("Error, must specify --genome_lib_dir or set env var CTAT_GENOME_LIB")
        
        genome_lib_dir = os.path.abspath(genome_lib_dir)
        
        args_parsed.gtf_filename = os.path.sep.join([genome_lib_dir, "ref_annot.gtf"])
        args_parsed.genome_fasta_filename = os.path.sep.join([genome_lib_dir, "ref_genome.fa"])
        args_parsed.cdna_fasta_filename = os.path.sep.join([genome_lib_dir, "ref_cdna.fasta"])

        args_parsed.str_out_dir = os.path.abspath(args_parsed.str_out_dir)
        
        workdir = args_parsed.str_out_dir + "/fi_workdir";
        workdir = os.path.abspath(workdir)
        if not os.path.exists(workdir):
            os.makedirs(workdir)
        
        checkpoints_dir = args_parsed.str_out_dir + "/chckpts_dir"
        checkpoints_dir = os.path.abspath(checkpoints_dir)
        if not os.path.exists(checkpoints_dir):
            os.makedirs(checkpoints_dir)
        
        chim_summary_files_list = args_parsed.chim_summary_files.split(",")
        
        chim_summary_files_adj = []
        for chim_summary_file in chim_summary_files_list:
            if os.stat(chim_summary_file).st_size == 0:
                print("Warning: No list of fusions in file: %s" % chim_summary_file, file=sys.stderr)
            else:
                chim_summary_files_adj.append(chim_summary_file)

        chim_summary_files_list = chim_summary_files_adj

        if not chim_summary_files_list:
            print("All fusion files: %s are empty. Exiting gracefully." % args_parsed.chim_summary_files, file=sys.stderr)
            sys.exit(0)

        if args_parsed.extract_fusion_reads_dir:
            args_parsed.extract_fusion_reads_dir = os.path.abspath(args_parsed.extract_fusion_reads_dir)

        if args_parsed.left_fq_filename:
            args_parsed.left_fq_filename = os.path.abspath(args_parsed.left_fq_filename)
            check_files_exist( [ args_parsed.left_fq_filename ])
                                                   
        if args_parsed.right_fq_filename:
            args_parsed.right_fq_filename = os.path.abspath(args_parsed.right_fq_filename)
            check_files_exist( [ args_parsed.right_fq_filename ])

        if args_parsed.samples_file:
            args_parsed.samples_file = os.path.abspath(args_parsed.samples_file)
            check_files_exist( [ args_parsed.samples_file ] )
        
        
        check_files_exist( [ args_parsed.gtf_filename,
                             args_parsed.genome_fasta_filename] + 
                           chim_summary_files_list )
        
        ## Construct pipeline
        pipeliner = Pipeliner(checkpoints_dir)


        ## Build the mini-contig containing just the two fusion genes, plus annotations in gtf format

        chim_summary_files = args_parsed.chim_summary_files.split(',')
        
        cmdstr = str( os.sep.join([UTILDIR, "fusion_pair_to_mini_genome_join.pl"]) +
                      " --fusions " + args_parsed.chim_summary_files +
                      " --gtf " + args_parsed.gtf_filename +
                      " --genome_fa " + args_parsed.genome_fasta_filename +
                      " --shrink_introns --max_intron_length 1000 " +
                      " --out_prefix " + os.sep.join([args_parsed.str_out_dir, args_parsed.out_prefix] ) )
        
        mergedContig_fasta_filename = os.sep.join([args_parsed.str_out_dir, args_parsed.out_prefix + ".fa"])
        mergedContig_gtf_filename = os.sep.join([args_parsed.str_out_dir, args_parsed.out_prefix + ".gtf"])
        
        pipeliner.add_commands([Command(cmdstr,"fusion_contigs.ok")])
        

        # symlink them in the workdir
        workdir_mergedContig_fasta_filename = os.sep.join([workdir, args_parsed.out_prefix + ".fa"])
        cmdstr = str("ln -s " + mergedContig_fasta_filename + " " + workdir_mergedContig_fasta_filename)
        pipeliner.add_commands([Command(cmdstr, "symlink_contigs_file_workdir")])
        
                
        workdir_mergedContig_gtf_filename = os.sep.join([workdir, args_parsed.out_prefix + ".gtf"])
        cmdstr = str("ln -s " + mergedContig_gtf_filename + " " + workdir_mergedContig_gtf_filename)
        pipeliner.add_commands([Command(cmdstr, "symlink_gtf_file_workdir.ok")])
                
        ## build a cytoband file
        cytoband_file = os.sep.join([args_parsed.str_out_dir, "cytoBand.txt"])
        cmdstr = str( os.sep.join([UTILDIR, "fasta_and_gtf_to_cytoband.pl"]) +
                      " " + mergedContig_fasta_filename + " " + mergedContig_gtf_filename +
                      " > " + cytoband_file )

        pipeliner.add_commands([Command(cmdstr, "cytoband.ok")])

        ## Convert the gtf to bed format for easier viewing
        mergedContig_bed_filename = os.sep.join([args_parsed.str_out_dir, args_parsed.out_prefix + ".bed"])
        
        cmdstr = str(UTILDIR + "/gtf_gene_to_bed.pl " + mergedContig_gtf_filename +
                     " > " + mergedContig_bed_filename)

        pipeliner.add_commands([Command(cmdstr, "merged_contig_gtf_to_bed.ok")])

        self.sort_and_index_bed(mergedContig_bed_filename, pipeliner)
        

        # index the fasta file
        cmdstr = str("samtools faidx " + mergedContig_fasta_filename)
        pipeliner.add_commands([Command(cmdstr, "merged_contig_fai.ok")])
        
        
        ##########
        # Run STAR
        
        cmdstr = None

        if args_parsed.fusion_contigs_only:
            cmdstr = str(os.path.sep.join([UTILDIR, "run_FI_STAR.pl"]) +
                     " --genome " + workdir_mergedContig_fasta_filename +
                     " -G " + workdir_mergedContig_gtf_filename + " --CPU " + str(args_parsed.CPU) +  
                     " --out_prefix " + args_parsed.out_prefix + ".star" +
                     " --out_dir " + workdir )
        else:

            ###############
            ## patched fusion-genome for STAR
            ###############

            cmdstr = str( os.path.sep.join([UTILDIR, "run_FI_STAR.pl"]) +
                          " --genome " + args_parsed.genome_fasta_filename +
                          " --patch " + workdir_mergedContig_fasta_filename +
                          " -G " + workdir_mergedContig_gtf_filename + " --CPU " + str(args_parsed.CPU) +  
                          " --out_prefix " + args_parsed.out_prefix + ".star" +
                          " --out_dir " + workdir )   


            if args_parsed.only_fusion_reads:
                cmdstr += " --only_fusion_reads "
            elif args_parsed.capture_genome_alignments:
                cmdstr += " --capture_genome_alignments "


        if args_parsed.samples_file:
            cmdstr += " --samples_file {} ".format(args_parsed.samples_file)
        else:
            # reads direct:
            cmdstr += " --reads \"" +  args_parsed.left_fq_filename + " " + args_parsed.right_fq_filename + "\""

        
        if args_parsed.aligner_path:
            cmdstr += " --star_path " + args_parsed.aligner_path


        star_bam_file = os.sep.join([workdir, args_parsed.out_prefix + ".star.sortedByCoord.out.bam"])


        pipeliner.add_commands([Command(cmdstr, "run_STAR.ok")])
        
        
        # mark duplicate reads
        star_dups_marked_bam_file = os.sep.join([workdir, args_parsed.out_prefix + ".star.cSorted.dupsMarked.bam"])

        cmdstr = str("java -Xmx2G -jar {} I={} O={} M={} TMP_DIR={} VALIDATION_STRINGENCY=SILENT ".format(os.sep.join([BASEDIR, "plugins", "MarkDuplicates.jar"]),
                                                                            star_bam_file,
                                                                            star_dups_marked_bam_file,
                                                                            star_dups_marked_bam_file + ".stats",
                                                                                    workdir))

        
        pipeliner.add_commands([Command(cmdstr, "mark_dup_reads.ok")])


        self.get_fusion_and_spanning_reads(args_parsed, workdir_mergedContig_gtf_filename,
                                           workdir_mergedContig_fasta_filename, star_dups_marked_bam_file, pipeliner)

        bam_files_list = [star_dups_marked_bam_file] # used to have more than one... leaving it like this for now.

        ###########################
        ## coalesce the fusion info
        ###########################
            
        fusion_junction_info_files_list = []
        fusion_junction_reads_list = []
        
        fusion_spanning_info_files_list = []
        fusion_spanning_reads_list = []


        for bam_file in bam_files_list:
            fusion_junction_info_files_list.append(bam_file + ".fusion_junction_info")
            fusion_junction_reads_list.append(bam_file + ".fusion_junc_reads.sam")

            fusion_spanning_info_files_list.append(bam_file + ".fusion_spanning_info")
            fusion_spanning_reads_list.append(bam_file + ".fusion_span_reads.sam")
            



        fusion_summary_file = os.sep.join([workdir, args_parsed.out_prefix + ".fusion_preds.coalesced.summary"]) 

        cmdstr = str( os.sep.join([UTILDIR, "coalesce_junction_and_spanning_info.pl"]) + " " +
                      ",".join(fusion_junction_info_files_list) + " " +
                      ",".join(fusion_spanning_info_files_list) +
                      " > " + fusion_summary_file )
        
        pipeliner.add_commands([Command(cmdstr, "coalesce_junc_n_span.ok")]) 
        
        

        ## need to filter based on remaining fusion support.
        fusion_summary_min_score_thresh_file = fusion_summary_file + ".min_frag_thresh"

        cmdstr = str(os.sep.join([UTILDIR, "filter_fusions_by_frag_thresholds.pl"]) +
                     " --min_junction_reads " + str(args_parsed.min_junction_reads) +
                     " --min_sum_frags " + str(args_parsed.min_sum_frags) +
                     " --min_novel_junction_support " + str(args_parsed.min_novel_junction_support) +
                     " --min_spanning_frags_only " + str(args_parsed.min_spanning_frags_only) +
                    " --fusion_preds " + fusion_summary_file +
                     " --require_LDAS " + str(args_parsed.require_LDAS) +
                     " > " + fusion_summary_min_score_thresh_file)
        

        pipeliner.add_commands([Command(cmdstr, "filter_by_frag_threshs.ok")]) 
        
        
        if args_parsed.include_Trinity or args_parsed.prep_for_IGV:

            #################################################################
            ## consolidate the Fusion Inspector reads into a single bam files
            #################################################################

            ## Junction reads

            summary_junctions_reads_list_filename = fusion_summary_file + ".fusion_junction_read_accs"
            cmdstr = str(os.sep.join([UTILDIR, "column_extractions.pl"]) +
                         " " + fusion_summary_file +
                         " LeftGene,RightGene,JunctionReads " +
                         " > " + summary_junctions_reads_list_filename)

            pipeliner.add_commands([Command(cmdstr, "prep_igv_extract_junc_reads.ok")]) 


            ## //TODO: Separate this into two steps: retrieve, then do bam conversion, to ensure retrieval works via exit code.

            consolidated_junction_reads_bam =  os.sep.join([args_parsed.str_out_dir, args_parsed.out_prefix + ".junction_reads.bam"])
            cmdstr = str(UTILDIR + "/retrieve_fusion_junction_reads_by_accession.pl " + summary_junctions_reads_list_filename
                         + " " + ",".join(fusion_junction_reads_list) +
                         " | samtools view -@ " + str(args_parsed.CPU) + " -bT " + mergedContig_fasta_filename + " - " +
                         " | samtools sort -@ " + str(args_parsed.CPU) + " - -o " + consolidated_junction_reads_bam)
            cmdstr = "bash -c \"set -eof pipefail; {}\"".format(cmdstr)
            
            pipeliner.add_commands([Command(cmdstr, "prep_igv_junc_reads_bam.ok")]) 

            cmdstr = "samtools index " + consolidated_junction_reads_bam
            
            pipeliner.add_commands([Command(cmdstr, "samtools_idx_junc_reads_bam.ok")]) 

            if args_parsed.prep_for_IGV:
                self.bam_to_bed(consolidated_junction_reads_bam, pipeliner)


            ## Spanning reads

            summary_spanning_reads_list_filename = fusion_summary_file + ".fusion_spanning_read_accs"
            cmdstr = str(os.sep.join([UTILDIR, "column_extractions.pl"]) +
                         " " + fusion_summary_file +
                         " LeftGene,RightGene,SpanningFrags " +
                         " > " + summary_spanning_reads_list_filename)

            pipeliner.add_commands([Command(cmdstr, "span_reads_acc.ok")]) 

            ## //TODO: Separate this into two steps: retrieve, then do bam conversion, to ensure retrieval works via exit code.

            consolidated_spanning_reads_bam =  os.sep.join([args_parsed.str_out_dir, args_parsed.out_prefix + ".spanning_reads.bam"])
            cmdstr = str(UTILDIR + "/retrieve_fusion_spanning_reads_by_accession.pl " + summary_spanning_reads_list_filename
                         + " " + ",".join(fusion_spanning_reads_list) +
                         " | samtools view -@ " + str(args_parsed.CPU) + " -bT " + mergedContig_fasta_filename + " - " +
                         " | samtools sort -@ " + str(args_parsed.CPU) + " - -o " + consolidated_spanning_reads_bam)
            # + " || : ") # again, cant afford for this to fail due to lack of evidence reads.

            pipeliner.add_commands([Command(cmdstr, "prep_spanning_reads.ok")])             

            cmdstr = "samtools index " + consolidated_spanning_reads_bam
            pipeliner.add_commands([Command(cmdstr, "samtools_index_span_reads_bam.ok")]) 

            if args_parsed.prep_for_IGV:
                self.bam_to_bed(consolidated_spanning_reads_bam, pipeliner)


            # consolidate all fusion-contig aligned reads into a single bam file
            consolidated_bam_file =  os.sep.join([args_parsed.str_out_dir, args_parsed.out_prefix  + ".consolidated"])
            
            cmdstr = str(UTILDIR + "/consolidate_bams_and_uniq_reads.pl " +
                         workdir_mergedContig_fasta_filename + " " +
                         ",".join(bam_files_list) + " " +
                         consolidated_bam_file)

            consolidated_bam_file += ".cSorted.bam"

            pipeliner.add_commands([Command(cmdstr, "consolidate_bam_and_uniq_readss.ok")]) 
            

            workdir_consolidated_bam_file = os.sep.join([workdir, args_parsed.out_prefix  + ".consolidated.bam"])
            
            cmdstr = "ln -s " + consolidated_bam_file + " " + workdir_consolidated_bam_file
            pipeliner.add_commands([Command(cmdstr, "symlink_consol_bam.ok")]) 
            
            if args_parsed.include_Trinity:

                ############################
                # run genome-guided Trinity
                ############################


                trinity_out_dir = os.sep.join([workdir, "trinity_GG"])
                trinity_fasta_filename = trinity_out_dir + "/Trinity-GG.fasta"

                cmdstr = str(TRINITY_HOME + "/Trinity --genome_guided_bam " + workdir_consolidated_bam_file +
                             " --max_memory 20G --genome_guided_max_intron 1000000 --CPU " +  str(args_parsed.CPU) + " --min_contig_length 100 " +
                             " --output " + trinity_out_dir)

                pipeliner.add_commands([Command(cmdstr, "run_trinity.ok")]) 

                ## Run TrinityGG, reconstruct fusion transcripts locally via de novo assembly
                trinGG_fusion_gff3 = self.add_trinfusion_gmap_subpipe(args_parsed, workdir_mergedContig_fasta_filename,
                                                                      workdir_mergedContig_gtf_filename, trinity_fasta_filename, pipeliner, workdir)
                
                # merge de novo assembly fusion results w/ read-based fusion results:
                fusion_summary_w_trinity = fusion_summary_min_score_thresh_file + ".wTrinityGG"
                cmdstr = str(UTILDIR + "/add_TrinityGG_to_fusion_summary.pl " + fusion_summary_min_score_thresh_file +
                             " " + trinGG_fusion_gff3 +
                             " > " + fusion_summary_w_trinity)
                
                pipeliner.add_commands([Command(cmdstr, "add_trinity_fusions_to_summary.ok")]) 
                
                fusion_summary_min_score_thresh_file = fusion_summary_w_trinity  ## NOTE, VARIABLE REPLACEMENT HERE INCL TRINITY RESULTS


            if args_parsed.prep_for_IGV:
                ## just make the coords file

                cmdstr = str(UTILDIR + "/SAM_to_frag_coords.pl --sam " + workdir_consolidated_bam_file +
                             " --max_insert_size 100000 "); 

                pipeliner.add_commands([Command(cmdstr, "prep_igv_sam_frag_coordss.ok")]) 

                ## Prep IGV fusion junction view

                frag_coords_file = workdir_consolidated_bam_file + ".frag_coords"
                igv_junc_view_file = os.sep.join([args_parsed.str_out_dir, args_parsed.out_prefix + ".igv.FusionJuncSpan"])

                cmdstr = str(UTILDIR + "/fusion_summary_to_igv_JuncSpan_fmt.pl " + fusion_summary_file + " " +
                            frag_coords_file + " > " + igv_junc_view_file)

                pipeliner.add_commands([Command(cmdstr, "prep_igv_juncspan_fmt.ok")]) 

                


        ################################################################
        ## Perform some reformatting to get us to the star fusion format
        ################################################################



        # output file has extension: starFfmt

        starFfmt_file = fusion_summary_min_score_thresh_file + ".starFfmt"
        
        cmdstr = str(UTILDIR + "/starfmt_reformatter.pl --fusion_preds " + fusion_summary_min_score_thresh_file +
                     " > " + starFfmt_file)

        pipeliner.add_commands([Command(cmdstr, "starFfmt_convert.ok")]) 
        

        ####################
        ## Add splicing info
        ####################

        preds_including_splice_info_file = starFfmt_file + ".wSpliceInfo"

        cmdstr = str(UTILDIR + "/append_breakpoint_junction_info_via_FI_contigs.pl " +
                     starFfmt_file + " " +
                     mergedContig_fasta_filename +
                     " > " + preds_including_splice_info_file)

        pipeliner.add_commands([Command(cmdstr, "add_splice_info.ok")]) 

                

        ################################################
        ## Score and filter the final fusion predictions
        ################################################

        final_fusions_file = os.sep.join([args_parsed.str_out_dir, args_parsed.out_prefix + ".fusion_predictions"])
        
        cmdstr = str(UTILDIR + "/../FusionFilter/blast_and_promiscuity_filter.pl " +
                     " --fusion_preds " + preds_including_splice_info_file +
                     " --out_prefix " + final_fusions_file +
                     " --genome_lib_dir " + args_parsed.genome_lib_dir +
                     " --max_promiscuity " + str(args_parsed.max_promiscuity) +
                     " --min_pct_dom_promiscuity " + str(args_parsed.min_pct_dom_promiscuity) )

        pipeliner.add_commands([Command(cmdstr, "blast_filter.ok")]) 

        unabridged_final_fusions_file = final_fusions_file + ".final"
                
        ## make an abridged version that lacks the list of supporting reads.
        
        cmdstr = str(UTILDIR + "/column_exclusions.pl " + final_fusions_file + ".final" +
                     " JunctionReads,SpanningFrags,CounterFusionLeftReads,CounterFusionRightReads " +
                     " > " + final_fusions_file + ".final.abridged");
        pipeliner.add_commands([Command(cmdstr, "final_abridged.ok")]) 
        
        ## add FFPM calculations
        if args_parsed.left_fq_filename:
            cmdstr = str( os.path.sep.join([UTILDIR, "incorporate_FFPM_into_final_report.pl"]) +
                          " " + args_parsed.left_fq_filename +
                          " " + final_fusions_file + ".final.abridged" +
                          " > " + final_fusions_file + ".final.abridged.FFPM" )
            
            pipeliner.add_commands([Command(cmdstr, "add_FFPM.ok")])
            
        
        if args_parsed.prep_for_IGV:
            ## generate the fusion-inspector-web galaxy js 

            cmdstr = str( os.path.sep.join( [ UTILDIR, "create_fusion_inspector_igvjs.py" ] ) +
                          " --fusion_inspector_directory " + args_parsed.str_out_dir +
                          " --json_outfile " + os.path.sep.join( [ args_parsed.str_out_dir, args_parsed.out_prefix + ".fusion_inspector_web.json" ] ) +
                          " --file_prefix " + args_parsed.out_prefix )
            
            if args_parsed.include_Trinity:
                cmdstr = cmdstr + " --include_Trinity"


            pipeliner.add_commands([Command(cmdstr, "create_fi_igvjs.ok")])

            
        final_fusions_file = final_fusions_file + ".final.abridged.FFPM"

        ## annotate
        
        if (args_parsed.annotate):

            annotated_fusions_file = final_fusions_file + ".annotated"
            
            cmdstr = str(os.path.sep.join( [BASEDIR, "FusionAnnotator", "FusionAnnotator"] ) +
                         " --annotate {} ".format(final_fusions_file) +
                         " --genome_lib_dir {}".format(genome_lib_dir) +
                         " > {} ".format(annotated_fusions_file) )

            pipeliner.add_commands([Command(cmdstr, "fusion_annotator.ok")]) 

            final_fusions_file = annotated_fusions_file


        if (args_parsed.examine_coding_effect):
            
            coding_effect_file = final_fusions_file + ".coding_effect"
            
            cmdstr = str(os.path.sep.join( [BASEDIR, "FusionAnnotator", "util", "fusion_to_coding_region_effect.pl"] ) +
                         " --fusions {} ".format(final_fusions_file) +
                         " --genome_lib_dir {}".format(genome_lib_dir) +
                         " > {} ".format(coding_effect_file) )

            pipeliner.add_commands([Command(cmdstr, "fusion_coding_region_effect.ok")]) 

            final_fusions_file = coding_effect_file


        if args_parsed.extract_fusion_reads_dir:

            fusion_reads_dir = args_parsed.extract_fusion_reads_dir
            if not os.path.exists(fusion_reads_dir):
                os.makedirs(fusion_reads_dir)

            cmdstr = str(os.path.sep.join( [BASEDIR, "util", "misc", "get_fusion_evidence_fastqs.pl"]) +
                         " " + unabridged_final_fusions_file + " "  + args_parsed.left_fq_filename + " ")
            
            if args_parsed.right_fq_filename:
                cmdstr += args_parsed.right_fq_filename
            else:
                cmdstr += "NONE"

            cmdstr += " " + args_parsed.extract_fusion_reads_dir

            pipeliner.add_commands([Command(cmdstr, "get_fusion_evidence_fqs.ok")]) 
                
        
        ## cleanup
        if args_parsed.cleanup:

            workdir_cleaned_file = os.path.sep.join([args_parsed.str_out_dir, "workdir.cleaned"])
            cmdstr = "/bin/rm -rf " + workdir
            
            pipeliner.add_commands([Command(cmdstr, "final_cleanup.ok")]) 

                    

        ## Run it
        pipeliner.run()
    
    
    def get_fusion_and_spanning_reads (self, args_parsed, mergedContig_gtf_filename, mergedContig_fasta_filename, bam_file, pipeliner):
        
        ## extract the fusion JUNCTION reads
        fusion_junction_reads_sam_file = bam_file + ".fusion_junc_reads.sam"
        fusion_junction_info_file = bam_file + ".fusion_junction_info"
        
        cmdstr = str(os.sep.join([UTILDIR, "get_fusion_JUNCTION_reads_from_fusion_contig_bam.pl"]) +
                     " --gtf_file " + mergedContig_gtf_filename +
                     " --MIN_ALIGN_PER_ID " + str(args_parsed.min_per_id) +
                     " --bam " + bam_file + " > " + fusion_junction_reads_sam_file)

        pipeliner.add_commands([Command(cmdstr, "get_fusion_JUNCTION_reads_from_bam.ok")]) 

        if args_parsed.write_intermediate_results:
            self.sort_sam_to_bam(fusion_junction_reads_sam_file, mergedContig_fasta_filename, lcmd_commands)

            ## convert the fusion JUNCTION reads sam file to bed format
            fusion_junction_reads_bed_file = bam_file + ".fusion_junc_reads.bed"
            cmdstr = str(UTILDIR + "/SAM_to_bed.pl " + fusion_junction_reads_sam_file +
                         " > " + fusion_junction_reads_bed_file)

            pipeliner.add_commands([Command(cmdstr, "fusion_junc_reads_to_bed_intermediates.ok")])
            
            self.sort_and_index_bed(fusion_junction_reads_bed_file, pipeliner)
            

        
        ## extract the fusion SPANNING reads
        fusion_spanning_reads_sam_file = bam_file + ".fusion_span_reads.sam"
        fusion_spanning_reads_info_file = bam_file + ".fusion_spanning_info"

        cmdstr = str(os.sep.join([UTILDIR, "get_fusion_SPANNING_reads_from_bam.from_chim_summary.pl"]) + 
                     " --gtf_file " + mergedContig_gtf_filename +
                     " --MIN_ALIGN_PER_ID " + str(args_parsed.min_per_id) +
                     " --bam " + bam_file +
                     " --junction_info " + fusion_junction_info_file + 
                     " > " + fusion_spanning_reads_sam_file)

        pipeliner.add_commands([Command(cmdstr, "get_fusion_SPANNING_reads_from_bam.ok")]) 

        if args_parsed.write_intermediate_results:
            self.sort_sam_to_bam(fusion_spanning_reads_sam_file, mergedContig_fasta_filename, pipeliner)

            ## convert the fusion JUNCTION reads sam file to bed format
            fusion_spanning_reads_bed_file = bam_file + ".fusion_span_reads.bed"
            cmdstr = str(UTILDIR + "/SAM_pair_to_bed.pl " + fusion_spanning_reads_sam_file +
                         " > " + fusion_spanning_reads_bed_file)

            pipeliner.add_commands([Command(cmdstr, "spanning_reads_bed_intermediate.ok")]) 

            self.sort_and_index_bed(fusion_spanning_reads_bed_file, pipeliner)


    def sort_and_index_bed(self, bed_file, pipeliner, checkpoint_token_prefix=None):

        if checkpoint_token_prefix is None:
            checkpoint_token_prefix = os.path.basename(bed_file)
        
        # sort by contig name followed by coordinate
        sorted_bed_file = bed_file + ".sorted.bed"

        cmdstr = str("sort -k1,1 -k2,2n " + bed_file + " > " + sorted_bed_file)
        
        
        pipeliner.add_commands([Command(cmdstr, checkpoint_token_prefix + ".bedsort.ok")]) 

        
        # index using tabix (preferred for IGV-web)
        cmdstr = str("bgzip -f " + sorted_bed_file)
        pipeliner.add_commands([Command(cmdstr, checkpoint_token_prefix + ".bgzip.ok")])
        
        cmdstr = str("tabix -p bed " + sorted_bed_file + ".gz")
        pipeliner.add_commands([Command(cmdstr, checkpoint_token_prefix + ".tabix.ok")])

        return





    def sort_sam_to_bam(self, sam_file, mergedContig_fasta_filename, pipeliner, checkpoint_token_prefix=None):

        
        if checkpoint_token_prefix is None:
            checkpoint_token_prefix = os.path.basename(sam_file) 


        cmdstr = str("set -o pipefail & samtools view -bT " + mergedContig_fasta_filename + " " + sam_file +
                     " | samtools sort - -o " + sam_file + ".bam")
        
        pipeliner.add_commands([Command(cmdstr, checkpoint_token_prefix + ".samToBam.ok")])
        
        
        # index it
        cmdstr = str("samtools index " + sam_file + ".bam")
        pipeliner.add_commands([Command(cmdstr, checkpoint_token_prefix + ".samtools_idx.ok")])
        

        return



    def bam_to_bed(self, bam_file, pipeliner, checkpoint_token_prefix=None):
        
        if checkpoint_token_prefix is None:
            checkpoint_token_prefix = os.path.basename(bam_file) 


        
        ## convert the reads bam file to bed format
        cmdstr = str(UTILDIR + "/SAM_pair_to_bed.pl " + bam_file +
                     " > " + bam_file + ".bed")

        pipeliner.add_commands([Command(cmdstr, checkpoint_token_prefix + ".bam_to_bed.ok")])

        
        self.sort_and_index_bed(bam_file + ".bed", pipeliner, checkpoint_token_prefix)

        return


    
    def add_trinfusion_gmap_subpipe(self, args_parsed, mergedContig_fasta_filename, mergedContig_gtf_filename,
                                    trinity_fasta_filename, pipeliner, workdir):

        gmap_gff3_output_filename = os.sep.join([workdir, args_parsed.out_prefix + ".gmap_trinity_GG.gff3"])

        cmdstr = str(TRINITY_HOME + "/util/misc/process_GMAP_alignments_gff3_chimeras_ok.pl " +
                     "--genome " + mergedContig_fasta_filename + " --transcripts " + trinity_fasta_filename +
                     " --no_chimera > " + gmap_gff3_output_filename)

        pipeliner.add_commands([Command(cmdstr, "trinity_gmap_alignment.ok")])

        ## extract the Trinity fusion transcripts
        trinity_fusion_trans_filename = os.sep.join([args_parsed.str_out_dir, args_parsed.out_prefix + ".gmap_trinity_GG.fusions.gff3"])
        cmdstr = str(os.sep.join([UTILDIR, "get_Trinity_fusion_alignments_from_gff3.pl"]) + " " + mergedContig_gtf_filename +
                     " " + gmap_gff3_output_filename + " > " + trinity_fusion_trans_filename)

        pipeliner.add_commands([Command(cmdstr, "trinity_fusion_trans_extraction_gff3.ok")])


        ## extract the Trinity Fusion transcripts
        trinityGG_fusion_fasta = os.sep.join([args_parsed.str_out_dir, args_parsed.out_prefix + ".gmap_trinity_GG.fusions.fasta"])
        cmdstr = str(os.sep.join([UTILDIR, "get_Trinity_fusion_fasta_seqs.pl"]) + " " + trinity_fasta_filename + " " + trinity_fusion_trans_filename +
                     " > " + trinityGG_fusion_fasta)
        pipeliner.add_commands([Command(cmdstr, "trinity_fusion_trans_extraction_fasta.ok")])
                    
        # convert fusion trans to bed
        trinity_fusion_trans_bed_filename = trinity_fusion_trans_filename + ".bed"
        min_per_id = 95
        cmdstr = str(UTILDIR + "/transcript_gff3_to_bed.pl " + trinity_fusion_trans_filename +
                     " " + str(min_per_id) + " > " + trinity_fusion_trans_bed_filename)

        pipeliner.add_commands([Command(cmdstr, "trinity_fusion_trans_gff3_to_bed.ok")])
        
        self.sort_and_index_bed(trinity_fusion_trans_bed_filename, pipeliner, "trinity_fusion")
        
        return (trinity_fusion_trans_filename) # trinGG fusion gff3 file w/ breakpoints encoded



def check_files_exist(files_lst):

    missing = False
    for file in files_lst:
        if not os.path.exists(file):
            print("Error, cannot locate file: {}\n".file(file), file=sys.stderr)
            missing = True

    if missing:
        raise RuntimeError("Error, missing files as indicated")


def contains_fusions (fusion_files):

    # just need to find one file that contains at least one fusion.

    for fusion_file in fusion_files.split(","):

        with open(fusion_file) as f:
            for line in f:
                if line[0] != '#' and re.search("--", line):
                    return True


    return False # no fusions listed


    
if __name__ == "__main__":

    # quickly check and see if there are fusions to explore... if not, then exit gracefully
    for i, item in enumerate(sys.argv):
        if item == "--fusions":
            fusion_file = sys.argv[i+1]
            if not contains_fusions(fusion_file):
                print("No fusions listed in input file: {}, exiting gracefully.".format(fusion_file), file=sys.stderr)
                sys.exit(0)


    # Needed to run, calls the script
    FusionInspector().run()
    


